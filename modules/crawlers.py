# modules/crawlers.py
"""
ë‹¤ì–‘í•œ ë³´ì•ˆ ë‰´ìŠ¤ ì›¹ì‚¬ì´íŠ¸ ë° RSS í”¼ë“œë¥¼ í¬ë¡¤ë§í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.
- NCSC ë³´ì•ˆê³µì§€ (Selenium)
- KRCERT ë³´ì•ˆê³µì§€ (RSS)
- ë³´ì•ˆë‰´ìŠ¤ (RSS)
- ë°ì¼ë¦¬ì‹œí (RSS)
"""

import time
import urllib.request
import xml.etree.ElementTree as ET
import requests
from bs4 import BeautifulSoup

# Selenium ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.options import Options

# ë‹¤ë¥¸ ëª¨ë“ˆì—ì„œ í•„ìš”í•œ í•¨ìˆ˜ ë° ì„¤ì •ê°’ ì„í¬íŠ¸
from config import ssl_context
from .utils import date_re, send_slack_message
from .notion_handler import Duplicate_check, create_notion_page
from .gemini_handler import summarize_text, details_text


def crawl_ncsc_page():
    """
    NCSC(êµ­ê°€ì‚¬ì´ë²„ì•ˆë³´ì„¼í„°) ì›¹ì‚¬ì´íŠ¸ì˜ 'ë³´ì•ˆê³µì§€' ê²Œì‹œíŒì—ì„œ ìµœì‹  ê²Œì‹œê¸€ì„ í¬ë¡¤ë§í•©ë‹ˆë‹¤.
    """
    source_name = "NCSC ë³´ì•ˆê³µì§€"
    driver = None
    print(f"--- {source_name} í¬ë¡¤ë§ ì‹œì‘ ---")
    try:
        options = Options()
        options.add_argument('--headless')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument("--disable-gpu")
        options.add_argument("--window-size=1920,1080")
        options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36")

        try:
            service = Service(ChromeDriverManager().install())
            driver = webdriver.Chrome(service=service, options=options)
        except Exception as e:
            print(f"[{source_name}-ERROR] ChromeDriver ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}")
            send_slack_message(f"[ERROR] {source_name} - ChromeDriver ì„¤ì • ì˜¤ë¥˜: {e}")
            return

        target_url = "https://www.ncsc.go.kr:4018"
        driver.get(target_url)
        print(f"[{source_name}-INFO] NCSC ì›¹ì‚¬ì´íŠ¸ ì ‘ì† ì‹œë„: {target_url}")

        driver.execute_script("goSubMenuPage('020000','020200')")
        print(f"[{source_name}-INFO] ë³´ì•ˆê³µì§€ ë©”ë‰´ë¡œ ì´ë™ ì‹¤í–‰ (goSubMenuPage('020000','020200'))")

        time.sleep(5)

        soup = BeautifulSoup(driver.page_source, 'html.parser')

        board_list_table = soup.find('table', class_='board_list')
        if not board_list_table:
            message = f"[{source_name}-WARN] ê²Œì‹œíŒ ëª©ë¡ í…Œì´ë¸”('table.board_list')ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            print(message)
            send_slack_message(f"[WARNING] {message} (URL: {driver.current_url})")
            return

        tr_tags = board_list_table.find('tbody').find_all('tr')
        if not tr_tags:
            print(f"[{source_name}-INFO] ê²Œì‹œíŒì— ê²Œì‹œê¸€ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"[{source_name}-INFO] {len(tr_tags)}ê°œì˜ ê²Œì‹œê¸€ í–‰ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤. ê° í•­ëª© ì²˜ë¦¬ ì‹œì‘...")

        items_processed = 0
        for tr_tag in tr_tags:
            items_processed +=1
            td_tags = tr_tag.find_all('td')
            title_cell = td_tags[1]
            a_tag = title_cell.find('a')

            if a_tag and a_tag.has_attr('onclick'):
                article_title = a_tag.text.strip()

                onclick_script = a_tag['onclick']
                print(f"  [{source_name}-INFO] '{article_title}' ìƒì„¸ í˜ì´ì§€ ì´ë™ ì‹œë„ (onclick: {onclick_script})")
                driver.execute_script(onclick_script)
                time.sleep(3)

                article_url = driver.current_url

                posting_date_str = td_tags[2].text.strip()
                posting_date = date_re(posting_date_str)

                if not posting_date:
                    print(f"  [{source_name}-SKIP] ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨ í•­ëª©: {article_title} (ì›ë³¸ ë‚ ì§œ: {posting_date_str})")
                    driver.back()
                    time.sleep(2)
                    continue

                duplicate_status = Duplicate_check(article_url)
                if duplicate_status == 0:
                    print(f"  [{source_name}-PROCESSING] ìƒˆ í•­ëª©: {article_title}")
                    
                    # NCSCëŠ” ìƒì„¸ ë³¸ë¬¸ í¬ë¡¤ë§ì´ ë³µì¡í•˜ë¯€ë¡œ, ì œëª© ê¸°ë°˜ìœ¼ë¡œ ë‚´ìš©ì„ ìƒì„±í•©ë‹ˆë‹¤.
                    # ë§Œì•½ ì‹¤ì œ ë³¸ë¬¸ì„ ë¶„ì„í•˜ê³  ì‹¶ë‹¤ë©´, ì•„ë˜ ì£¼ì„ ì²˜ë¦¬ëœ ë¡œì§ì„ í™œì„±í™”í•˜ê³ 
                    # NCSC ì›¹ì‚¬ì´íŠ¸ êµ¬ì¡°ì— ë§ê²Œ ë³¸ë¬¸ ë‚´ìš© ì„ íƒìë¥¼ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.
                    page_text_content = article_title 
                    
                    # summary_for_notion = summarize_text(page_text_content)
                    # details_for_notion = details_text(page_text_content)
                    
                    # ì„ì‹œë¡œ ì œëª©ì„ ìš”ì•½ ë° ìƒì„¸ ë‚´ìš©ìœ¼ë¡œ ì‚¬ìš©
                    summary_for_notion = f"NCSC ë³´ì•ˆê³µì§€: {article_title}"
                    details_for_notion = f"## ğŸ” ë‰´ìŠ¤ ìš”ì•½\n\nNCSC(êµ­ê°€ì‚¬ì´ë²„ì•ˆë³´ì„¼í„°)ì—ì„œ '{article_title}'ì— ëŒ€í•œ ë³´ì•ˆê³µì§€ë¥¼ ë°œí‘œí–ˆìŠµë‹ˆë‹¤.\n\n## ğŸ’¡ í•µì‹¬ í¬ì¸íŠ¸\n\n- ìì„¸í•œ ë‚´ìš©ì€ ì›ë¬¸ ë§í¬ë¥¼ ì°¸ì¡°í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."

                    create_notion_page(article_title, summary_for_notion, article_url, posting_date, "NCSC", details_for_notion)

                elif duplicate_status == 1:
                    print(f"  [{source_name}-SKIP] ì¤‘ë³µëœ í•­ëª©: {article_title}")
                else:
                    print(f"  [{source_name}-SKIP] ì¤‘ë³µ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ í•­ëª©: {article_title}")

                print(f"  [{source_name}-INFO] ëª©ë¡ í˜ì´ì§€ë¡œ ë³µê·€ ì¤‘...")
                driver.back()
                time.sleep(2)
            else:
                print(f"  [{source_name}-WARN] {items_processed}ë²ˆì§¸ í–‰ì—ì„œ ì œëª© ë§í¬(a_tag) ë˜ëŠ” onclick ì†ì„±ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"[{source_name}-ERROR] í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        current_url_info = ""
        if driver and hasattr(driver, 'current_url') and driver.current_url:
            current_url_info = f" (í˜„ì¬ URL: {driver.current_url})"
        send_slack_message(f"[ERROR] {source_name} í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ{current_url_info}: {e}")
    finally:
        if driver:
            driver.quit()
            print(f"[{source_name}-INFO] WebDriver ì¢…ë£Œë¨.")


def securityNotice_crawling():
    """KRCERT(í•œêµ­ì¸í„°ë„·ì§„í¥ì›) ë³´ì•ˆ ê³µì§€ RSS í”¼ë“œë¥¼ í¬ë¡¤ë§í•©ë‹ˆë‹¤."""
    source_name = "KRCERT ë³´ì•ˆê³µì§€"
    url = 'http://knvd.krcert.or.kr/rss/securityNotice.do'
    try:
        print(f"--- {source_name} í¬ë¡¤ë§ ì‹œì‘ ({url}) ---")
        with urllib.request.urlopen(url, context=ssl_context, timeout=15) as response:
            xml_data = response.read().decode('utf-8')

        root = ET.fromstring(xml_data)
        channel = root.find('channel')
        if channel is None:
            print(f"{source_name} RSS í”¼ë“œì—ì„œ 'channel' íƒœê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        items_processed = 0
        for item_elem in channel.findall('item'):
            items_processed +=1
            title = item_elem.findtext('title', default='ì œëª© ì—†ìŒ').strip()
            link_url = item_elem.findtext('link', default='').strip()
            original_content = item_elem.findtext('description', default='ë‚´ìš© ì—†ìŒ').strip()
            pub_date_str = item_elem.findtext('pubDate', default='').strip()
            category_ = "KRCERT"

            if not link_url:
                print(f"[{source_name}-SKIP] URL ì—†ëŠ” í•­ëª©: {title}")
                continue

            posting_date = date_re(pub_date_str)
            if not posting_date:
                print(f"[{source_name}-SKIP] ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨ í•­ëª©: {title} (ì›ë³¸ ë‚ ì§œ: {pub_date_str})")
                continue

            duplicate_status = Duplicate_check(link_url)
            if duplicate_status == 0:
                print(f"[{source_name}-PROCESSING] ìƒˆ í•­ëª©: {title}")
                summarized_content = summarize_text(original_content)
                details_content = details_text(original_content)

                if "ì‹¤íŒ¨" in summarized_content or "ì‹¤íŒ¨" in details_content:
                    send_slack_message(f"[WARN] {source_name} '{title}' ì²˜ë¦¬ ì¤‘ Gemini API ì‹¤íŒ¨. "
                                       f"ìš”ì•½: {summarized_content}, ìƒì„¸: {details_content}")

                create_notion_page(title, summarized_content, link_url, posting_date, category_, details_content)
            elif duplicate_status == 1:
                print(f"[{source_name}-SKIP] ì¤‘ë³µëœ í•­ëª©: {title}")
            else:
                 print(f"[{source_name}-SKIP] ì¤‘ë³µ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ í•­ëª©: {title}")

    except urllib.error.URLError as e:
        print(f"{source_name} RSS URL({url}) ì—´ê¸° ì‹¤íŒ¨: {e}")
        send_slack_message(f"[ERROR] {source_name} RSS URL ì—´ê¸° ì‹¤íŒ¨: {e}")
    except ET.ParseError as e:
        print(f"{source_name} RSS XML íŒŒì‹± ì‹¤íŒ¨: {e}")
        send_slack_message(f"[ERROR] {source_name} RSS XML íŒŒì‹± ì‹¤íŒ¨: {e}")
    except Exception as e:
        print(f"{source_name} í¬ë¡¤ë§ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")
        send_slack_message(f"[ERROR] {source_name} í¬ë¡¤ë§ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")


def boanNews_crawling():
    """ë³´ì•ˆë‰´ìŠ¤ RSS í”¼ë“œë¥¼ í¬ë¡¤ë§í•©ë‹ˆë‹¤. pubDateì™€ dc:date íƒœê·¸ë¥¼ ëª¨ë‘ í™•ì¸í•©ë‹ˆë‹¤."""
    source_name = "ë³´ì•ˆë‰´ìŠ¤"
    namespaces = {'dc': 'http://purl.org/dc/elements/1.1/'}

    try:
        urls = [
            'http://www.boannews.com/media/news_rss.xml?skind=5',
            'http://www.boannews.com/media/news_rss.xml?skind=6',
            'http://www.boannews.com/media/news_rss.xml?mkind=1'
        ]
        print(f"--- {source_name} í¬ë¡¤ë§ ì‹œì‘ ---")
        for rss_url in urls:
            print(f"  - {rss_url} ì²˜ë¦¬ ì¤‘...")
            try:
                response = requests.get(rss_url, timeout=15)
                response.raise_for_status()
                response.encoding = response.apparent_encoding
                root = ET.fromstring(response.text)
                channel = root.find('channel')

                if channel is None:
                    print(f"  [{source_name}-WARN] RSS ({rss_url})ì—ì„œ 'channel' íƒœê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    continue

                for item_elem in channel.findall('item'):
                    title = item_elem.findtext('title', default='ì œëª© ì—†ìŒ').strip()
                    link_url = item_elem.findtext('link', default='').strip()
                    original_content = item_elem.findtext('description', default='ë‚´ìš© ì—†ìŒ').strip()
                    category_ = "ë³´ì•ˆë‰´ìŠ¤"

                    pub_date_str = item_elem.findtext('pubDate', default='').strip()
                    if not pub_date_str:
                        dc_date_element = item_elem.find('dc:date', namespaces)
                        if dc_date_element is None:
                            dc_date_element = item_elem.find('{http://purl.org/dc/elements/1.1/}date')
                        if dc_date_element is not None and dc_date_element.text:
                            pub_date_str = dc_date_element.text.strip()

                    if not link_url:
                        print(f"  [{source_name}-SKIP] URL ì—†ëŠ” í•­ëª©: {title}")
                        continue
                    
                    posting_date = date_re(pub_date_str)
                    if not posting_date:
                        print(f"  [{source_name}-SKIP] ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨ í•­ëª©: {title} (ì›ë³¸ ë‚ ì§œ: '{pub_date_str}')")
                        continue

                    if rss_url.endswith('mkind=1') and "[ê¸´ê¸‰]" not in title:
                        continue

                    duplicate_status = Duplicate_check(link_url)
                    if duplicate_status == 0:
                        print(f"  [{source_name}-PROCESSING] ìƒˆ í•­ëª©: {title}")
                        summarized_content = summarize_text(original_content)
                        details_content = details_text(original_content)
                        if "ì‹¤íŒ¨" in summarized_content or "ì‹¤íŒ¨" in details_content:
                            send_slack_message(f"[WARN] {source_name} '{title}' ì²˜ë¦¬ ì¤‘ Gemini API ì‹¤íŒ¨. "
                                               f"ìš”ì•½: {summarized_content}, ìƒì„¸: {details_content}")
                        create_notion_page(title, summarized_content, link_url, posting_date, category_, details_content)
                    elif duplicate_status == 1:
                        print(f"  [{source_name}-SKIP] ì¤‘ë³µëœ í•­ëª©: {title}")
                    else:
                        print(f"  [{source_name}-SKIP] ì¤‘ë³µ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ í•­ëª©: {title}")

            except requests.exceptions.RequestException as e:
                print(f"  [{source_name}-ERROR] RSS ({rss_url}) ìš”ì²­ ì‹¤íŒ¨: {e}")
                send_slack_message(f"[ERROR] {source_name} RSS ({rss_url}) ìš”ì²­ ì‹¤íŒ¨: {e}")
                continue
            except ET.ParseError as e:
                print(f"  [{source_name}-ERROR] RSS ({rss_url}) XML íŒŒì‹± ì‹¤íŒ¨: {e}")
                send_slack_message(f"[ERROR] {source_name} RSS ({rss_url}) XML íŒŒì‹± ì‹¤íŒ¨: {e}")
                continue
    except Exception as e:
        print(f"{source_name} í¬ë¡¤ë§ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")
        send_slack_message(f"[ERROR] {source_name} í¬ë¡¤ë§ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")


def dailysecu_crawling():
    """ë°ì¼ë¦¬ì‹œí RSS í”¼ë“œë¥¼ í¬ë¡¤ë§í•©ë‹ˆë‹¤."""
    source_name = "ë°ì¼ë¦¬ì‹œí"
    url = 'https://www.dailysecu.com/rss/S1N2.xml'
    try:
        print(f"--- {source_name} í¬ë¡¤ë§ ì‹œì‘ ({url}) ---")
        try:
            response = requests.get(url, timeout=15)
            response.raise_for_status()
            response.encoding = response.apparent_encoding
            root = ET.fromstring(response.text)
            channel = root.find('channel')
            if channel is None:
                print(f"{source_name} RSS ({url})ì—ì„œ 'channel' íƒœê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return

            for item_elem in channel.findall('item'):
                title = item_elem.findtext('title', default='ì œëª© ì—†ìŒ').strip()
                link_url = item_elem.findtext('link', default='').strip()
                original_content = item_elem.findtext('description', default='ë‚´ìš© ì—†ìŒ').strip()
                category_ = "ë°ì¼ë¦¬ì‹œí"
                
                pub_date_str = item_elem.findtext('pubDate', default='').strip()
                if not pub_date_str:
                    dc_date_elem = item_elem.find('{http://purl.org/dc/elements/1.1/}date')
                    if dc_date_elem is not None and dc_date_elem.text:
                        pub_date_str = dc_date_elem.text.strip()

                if not link_url:
                    print(f"[{source_name}-SKIP] URL ì—†ëŠ” í•­ëª©: {title}")
                    continue

                posting_date = date_re(pub_date_str)
                if not posting_date:
                    print(f"[{source_name}-SKIP] ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨ í•­ëª©: {title} (ì›ë³¸ ë‚ ì§œ: {pub_date_str})")
                    continue

                duplicate_status = Duplicate_check(link_url)
                if duplicate_status == 0:
                    print(f"[{source_name}-PROCESSING] ìƒˆ í•­ëª©: {title}")
                    summarized_content = summarize_text(original_content)
                    details_content = details_text(original_content)
                    if "ì‹¤íŒ¨" in summarized_content or "ì‹¤íŒ¨" in details_content:
                        send_slack_message(f"[WARN] {source_name} '{title}' ì²˜ë¦¬ ì¤‘ Gemini API ì‹¤íŒ¨. "
                                           f"ìš”ì•½: {summarized_content}, ìƒì„¸: {details_content}")
                    create_notion_page(title, summarized_content, link_url, posting_date, category_, details_content)
                elif duplicate_status == 1:
                    print(f"[{source_name}-SKIP] ì¤‘ë³µëœ í•­ëª©: {title}")
                else:
                    print(f"[{source_name}-SKIP] ì¤‘ë³µ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ í•­ëª©: {title}")

        except requests.exceptions.RequestException as e:
            print(f"{source_name} RSS ({url}) ìš”ì²­ ì‹¤íŒ¨: {e}")
            send_slack_message(f"[ERROR] {source_name} RSS ({url}) ìš”ì²­ ì‹¤íŒ¨: {e}")
        except ET.ParseError as e:
            print(f"{source_name} RSS ({url}) XML íŒŒì‹± ì‹¤íŒ¨: {e}")
            send_slack_message(f"[ERROR] {source_name} RSS ({url}) XML íŒŒì‹± ì‹¤íŒ¨: {e}")
    except Exception as e:
        print(f"{source_name} í¬ë¡¤ë§ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")
        send_slack_message(f"[ERROR] {source_name} í¬ë¡¤ë§ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")